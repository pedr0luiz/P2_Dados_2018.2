{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador AutomÃ¡tico de Sentimento\n",
    "\n",
    "VocÃª foi contratado por uma empresa parar analisar como os clientes estÃ£o reagindo a um determinado produto no Twitter. A empresa deseja que vocÃª crie um programa que irÃ¡ analisar as mensagens disponÃ­veis e classificarÃ¡ como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereÃ§am destaque, disparem um foco de atenÃ§Ã£o da Ã¡rea de marketing.<br /><br />\n",
    "Como aluno de CiÃªncia dos Dados, vocÃª lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que Ã© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteÃºdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, vocÃª precisa implementar uma versÃ£o do classificador que \"aprende\" o que Ã© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "ApÃ³s validado, o seu protÃ³tipo poderÃ¡ tambÃ©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## InformaÃ§Ãµes do Projeto\n",
    "\n",
    "Prazo: 19/Set atÃ© Ã s 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terÃ¡ uma rubrica diferenciada.<br /><br />\n",
    "EntregÃ¡veis via GitHub: \n",
    "* Arquivo notebook com o cÃ³digo do classificador, seguindo as orientaÃ§Ãµes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃƒO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega IntermediÃ¡ria: Check 1 - APS 2\n",
    "\n",
    "AtÃ© o dia 10/Set Ã s 23:59, xlsx deve estar no Github com as seguintes evidÃªncias: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes jÃ¡ classificadas.\n",
    "\n",
    "SugestÃ£o de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. NÃ£o se esqueÃ§a de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. NÃ£o remover emojis.<br />\n",
    "* Corrigir separaÃ§Ã£o de espaÃ§os entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformaÃ§Ãµes que nÃ£o afetem a qualidade da informaÃ§Ã£o.\n",
    "\n",
    "Escreva o seu cÃ³digo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos arquivos em Excel\n",
    "\n",
    "nubank_treinamento = pd.read_excel('tweets_treinamento_p2.xlsx')\n",
    "nu_treino_sim = nubank_treinamento[nubank_treinamento['Avaliacao'] == 'sim']\n",
    "nu_treino_nao = nubank_treinamento[nubank_treinamento['Avaliacao'] == 'nao']\n",
    "nubank_teste = pd.read_excel('tweets_teste_p2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_caracteres(tabela, titulo):\n",
    "    a = tabela[titulo]\n",
    "    a = a.str.lower()\n",
    "\n",
    "    itens = ['.', ':', ';', '\"', \"'\", '?', '(', ')', '[',']',',', '\\n', '\\t']\n",
    "    i2 = ['?', '!']\n",
    "    #emojis = [â¤ ğŸ§¡ ğŸ’› ğŸ’š ğŸ’™ ğŸ’œ ğŸ–¤ ğŸ’” â£ ğŸ’• ğŸ’ ğŸ’“ ğŸ’— ğŸ’– ğŸ’˜ ğŸ’ğŸ˜€ ğŸ˜¬ ğŸ˜ ğŸ˜‚ ğŸ˜ƒ ğŸ˜„ ğŸ¤£ ğŸ˜… ğŸ˜† ğŸ˜‡ ğŸ˜‰ ğŸ˜Š ğŸ™‚ ğŸ™ƒ â˜º ğŸ˜‹ ğŸ˜Œ ğŸ˜ ğŸ˜˜ ğŸ˜— ğŸ˜™ ğŸ˜š ğŸ¤ª ğŸ˜œ ğŸ˜ ğŸ˜› ğŸ¤‘ ğŸ˜ ğŸ¤“ ğŸ§ ğŸ¤  ğŸ¤— ğŸ¤¡ ğŸ˜ ğŸ˜¶ ğŸ˜ ğŸ˜‘ ğŸ˜’ ğŸ™„ ğŸ¤¨ ğŸ¤” ğŸ¤« ğŸ¤­ ğŸ¤¥ ğŸ˜³ ğŸ˜ ğŸ˜Ÿ ğŸ˜  ğŸ˜¡ ğŸ¤¬ ğŸ˜” ğŸ˜• ğŸ™ â˜¹ ğŸ˜£ ğŸ˜– ğŸ˜« ğŸ˜© ğŸ˜¤ ğŸ˜® ğŸ˜± ğŸ˜¨ ğŸ˜° ğŸ˜¯ ğŸ˜¦ ğŸ˜§ ğŸ˜¢ ğŸ˜¥ ğŸ˜ª ğŸ¤¤ ğŸ˜“ ğŸ˜­ ğŸ¤© ğŸ˜µ ğŸ˜² ğŸ¤¯ ğŸ¤ ğŸ˜· ğŸ¤• ğŸ¤’ ğŸ¤® ğŸ¤¢ ğŸ¤§ ğŸ˜´ ğŸ’¤ ğŸ˜ˆ ğŸ‘¿ ğŸ‘¹ ğŸ‘º ğŸ’© ğŸ‘» ğŸ’€ â˜  ğŸ‘½ ğŸ¤– ğŸƒ ğŸ˜º ğŸ˜¸ ğŸ˜¹ ğŸ˜» ğŸ˜¼ ğŸ˜½ ğŸ™€ ğŸ˜¿ ğŸ˜¾ ğŸ‘ ğŸ¤² ğŸ™Œ ğŸ‘ ğŸ™ ğŸ¤ ğŸ‘ ğŸ‘ ğŸ‘Š âœŠ ğŸ¤› ğŸ¤œ ğŸ¤ âœŒ ğŸ¤˜ ğŸ¤Ÿ ğŸ‘Œ ğŸ‘ˆ ğŸ‘‰ ğŸ‘† ğŸ‘‡ â˜ âœ‹ ğŸ¤š ğŸ– ğŸ–– ğŸ‘‹ ğŸ¤™ ğŸ’ª ğŸ–• âœ ğŸ¤³ ğŸ’… ğŸ‘„ ğŸ‘… ğŸ‘‚ ğŸ‘ƒ ğŸ‘ ğŸ‘€ ğŸ§  ğŸ‘¤ ğŸ‘¥ ğŸ—£ ğŸ‘¶ ğŸ§’ ğŸ‘¦ ğŸ‘§ ğŸ§‘ ğŸ‘¨ ğŸ§” ğŸ‘±â€â™‚ï¸ ğŸ‘© ğŸ‘±â€â™€ï¸ ğŸ§“ ğŸ‘´ ğŸ‘µ ğŸ‘² ğŸ‘³â€â™€ï¸ ğŸ‘³â€â™‚ï¸ ğŸ§• ğŸ‘®â€â™€ï¸ ğŸ‘®â€â™‚ï¸ ğŸ‘©â€ğŸš’ ğŸ‘¨â€ğŸš’ ğŸ‘·â€â™€ï¸ ğŸ‘·â€â™‚ï¸ ğŸ‘©â€ğŸ­ ğŸ‘¨â€ğŸ­ ğŸ‘©â€ğŸ”§ ğŸ‘¨â€ğŸ”§ ğŸ‘©â€ğŸŒ¾ ğŸ‘¨â€ğŸŒ¾ ğŸ‘©â€ğŸ³ ğŸ‘¨â€ğŸ³ ğŸ‘©â€ğŸ¤ ğŸ‘¨â€ğŸ¤ ğŸ‘©â€ğŸ¨ ğŸ‘¨â€ğŸ¨ ğŸ‘©â€ğŸ« ğŸ‘¨â€ğŸ« ğŸ‘©â€ğŸ“ ğŸ‘¨â€ğŸ“ ğŸ‘©â€ğŸ’¼ ğŸ‘¨â€ğŸ’¼ ğŸ‘©â€ğŸ’» ğŸ‘¨â€ğŸ’» ğŸ‘©â€ğŸ”¬ ğŸ‘¨â€ğŸ”¬ ğŸ‘©â€ğŸš€ ğŸ‘¨â€ğŸš€ ğŸ‘©â€âš•ï¸ ğŸ‘¨â€âš•ï¸ ğŸ‘©â€âš–ï¸ ğŸ‘¨â€âš–ï¸ ğŸ‘©â€âœˆï¸ ğŸ‘¨â€âœˆï¸ ğŸ’‚â€â™€ï¸ ğŸ’‚â€â™‚ï¸ ğŸ•µï¸â€â™€ï¸ ğŸ•µï¸â€â™‚ï¸ ğŸ¤¶ ğŸ… ğŸ‘¼ ğŸ‘¸ ğŸ¤´ ğŸ‘° ğŸ¤µâ€â™€ï¸ ğŸ¤µ ğŸ•´ï¸â€â™€ï¸ ğŸ•´ ğŸ§™â€â™€ï¸ ğŸ§™â€â™‚ï¸ ğŸ§â€â™€ï¸ ğŸ§â€â™‚ï¸ ğŸ§šâ€â™€ï¸ ğŸ§šâ€â™‚ï¸ ğŸ§â€â™€ï¸ ğŸ§â€â™‚ï¸ ğŸ§œâ€â™€ï¸ ğŸ§œâ€â™‚ï¸ ğŸ§›â€â™€ï¸ ğŸ§›â€â™‚ï¸ ğŸ§Ÿâ€â™€ï¸ ğŸ§Ÿâ€â™‚ï¸ ğŸ™‡â€â™€ï¸ ğŸ™‡â€â™‚ï¸ ğŸ’â€â™€ï¸ ğŸ’â€â™‚ï¸ ğŸ™…â€â™€ï¸ ğŸ™…â€â™‚ï¸ ğŸ™†â€â™€ï¸ ğŸ™†â€â™‚ï¸ ğŸ¤·â€â™€ï¸ ğŸ¤·â€â™‚ï¸ ğŸ™‹â€â™€ï¸ ğŸ™‹â€â™‚ï¸ ğŸ¤¦â€â™€ï¸ ğŸ¤¦â€â™‚ï¸ ğŸ™â€â™€ï¸ ğŸ™â€â™‚ï¸ ğŸ™â€â™€ï¸ ğŸ™â€â™‚ï¸ ğŸ’‡â€â™€ï¸ ğŸ’‡â€â™‚ï¸ ğŸ’†â€â™€ï¸ ğŸ’†â€â™‚ï¸ ğŸ¤° ğŸ¤± ğŸš¶â€â™€ï¸ ğŸš¶â€â™‚ï¸ ğŸƒâ€â™€ï¸ ğŸƒâ€â™‚ï¸ ğŸ’ƒ ğŸ•º ğŸ‘¯â€â™€ï¸ ğŸ‘¯â€â™‚ï¸ ğŸ‘« ğŸ‘¬ ğŸ‘­ ğŸ’‘ ğŸ‘©â€â¤ï¸â€ğŸ‘© ğŸ‘¨â€â¤ï¸â€ğŸ‘¨ ğŸ’ ğŸ‘©â€â¤ï¸â€ğŸ’‹â€ğŸ‘© ğŸ‘¨â€â¤ï¸â€ğŸ’‹â€ğŸ‘¨ ğŸ‘ª ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ ğŸ‘©â€ğŸ‘©â€ğŸ‘¦ ğŸ‘©â€ğŸ‘©â€ğŸ‘§ ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ğŸ‘©â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘§â€ğŸ‘§ ğŸ‘©â€ğŸ‘¦ ğŸ‘©â€ğŸ‘§ ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ ğŸ‘©â€ğŸ‘§â€ğŸ‘§ ğŸ‘¨â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘§ ğŸ‘¨â€ğŸ‘§â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦ ğŸ‘¨â€ğŸ‘§â€ğŸ‘§ ğŸ‘š ğŸ‘• ğŸ§¥ ğŸ‘– ğŸ‘” ğŸ‘— ğŸ‘™ ğŸ‘˜ ğŸ’„ ğŸ’‹ ğŸ‘£ ğŸ§¦ ğŸ‘  ğŸ‘¡ ğŸ‘¢ ğŸ‘ ğŸ‘Ÿ ğŸ§¢ ğŸ‘’ ğŸ© ğŸ“ ğŸ‘‘ â›‘ ğŸ’ ğŸ‘ ğŸ‘› ğŸ‘œ ğŸ’¼ ğŸ‘“ ğŸ•¶ ğŸ§£ ğŸ§¤ ğŸ’ ğŸŒ‚ â˜‚]\n",
    "    for e in itens:\n",
    "        a = a.str.replace(e,'')\n",
    "    for e in i2:\n",
    "        a = a.str.replace(e,' {} '.format(e))\n",
    "\n",
    "    a = a.str.replace('Ã©','e')\n",
    "    a = a.str.replace('Ãª','e')\n",
    "    a = a.str.replace('Ã¡','a')\n",
    "    a = a.str.replace('Ã£','a')\n",
    "    a = a.str.replace('Ã´','o')\n",
    "    a = a.str.replace('Ã³','o')\n",
    "    a = a.str.replace('Ãº','u')\n",
    "    a = a.str.replace('Ã§','c')\n",
    "    a = a.str.replace('Ã­','i')\n",
    "    a = a.str.replace('@',' @')\n",
    "        \n",
    "    tabela[titulo] = a\n",
    "\n",
    "    return tabela\n",
    "\n",
    "def split_tweet(tabela, titulo):\n",
    "    a = tabela[titulo].str.split(' ')\n",
    "\n",
    "    nova = pd.DataFrame()\n",
    "    nova['palavras'] = []\n",
    "\n",
    "    for lista in a:\n",
    "        for e in ['' , ' ']:\n",
    "            while lista.count(e) != 0:\n",
    "                lista.remove(e)\n",
    "\n",
    "        for palavra in lista:\n",
    "            if '@' in palavra and palavra != '@nubank':\n",
    "                lista.remove(palavra) \n",
    "            if palavra[:4] == 'http':\n",
    "                lista.remove(palavra)\n",
    "        nova = nova.append({'palavras': lista}, ignore_index=True)\n",
    "                \n",
    "    return nova\n",
    "\n",
    "def tabela_palavras(tabela):\n",
    "    a = tabela['palavras']\n",
    "    prob = pd.DataFrame()\n",
    "    prob['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            prob = prob.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return prob['palavras']\n",
    "\n",
    "def tabela_tudo(tabela1, tabela2):\n",
    "    a = tabela1['palavras']\n",
    "    b = tabela2['palavras']\n",
    "    tudo = pd.DataFrame()\n",
    "    tudo['palavras'] = []\n",
    "    for lista in a:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    for lista in b:\n",
    "        for e in lista:\n",
    "            tudo = tudo.append({'palavras': e}, ignore_index=True)\n",
    "    \n",
    "    return tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "palavras_sim = tabela_palavras(split_tweet(limpar_caracteres(nu_treino_sim, 'Treinamento'), 'Treinamento'))\n",
    "num_sim = palavras_sim.value_counts()\n",
    "len_sim = len(num_sim)\n",
    "\n",
    "palavras_nao = tabela_palavras(split_tweet(limpar_caracteres(nu_treino_nao, 'Treinamento'), 'Treinamento'))\n",
    "num_nao = palavras_nao.value_counts()\n",
    "len_nao = len(num_nao)\n",
    "\n",
    "teste = split_tweet(limpar_caracteres(nubank_teste, 'Teste'), 'Teste')\n",
    "teste = teste.join(nubank_teste['Avaliacao'])\n",
    "\n",
    "tudo = tabela_tudo(split_tweet(limpar_caracteres(nu_treino_sim, 'Treinamento'), 'Treinamento'),split_tweet(limpar_caracteres(nu_treino_nao, 'Treinamento'), 'Treinamento'))\n",
    "total_palavras = len(tudo['palavras'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora vocÃª deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "VocÃª deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas nÃ£o sÃ£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e sÃ£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como nÃ£o relevante e nÃ£o sÃ£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como nÃ£o relevante e sÃ£o relevantes)\n",
    "\n",
    "ObrigatÃ³rio para grupos de 3 alunos:\n",
    "* Criar categorias intermediÃ¡rias de relevÃ¢ncia baseado na diferenÃ§a de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/Pedro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "teste[\"Avaliacao_nb\"] = pd.Series()\n",
    "teste[\"Resultado\"] = pd.Series()\n",
    "\n",
    "for linha in teste[\"palavras\"]:\n",
    "    p_sim = 1\n",
    "    p_nao = 1\n",
    "    p_naive = ''\n",
    "    for palavra in linha:\n",
    "        try:\n",
    "            p_sim *= (num_sim[palavra] + 1)/(len_sim + total_palavras)\n",
    "            p_nao *= (num_nao[palavra] + 1)/(len_nao + total_palavras)\n",
    "        except:\n",
    "            p_sim *= 1/(len_sim + total_palavras)\n",
    "            p_nao *= 1/(len_nao + total_palavras)\n",
    "    if p_sim > p_nao:\n",
    "        p_naive = 'sim'\n",
    "        teste[\"Avaliacao_nb\"][i] = \"sim\"\n",
    "        if teste['Avaliacao'][i] == p_naive:\n",
    "            teste[\"Resultado\"][i] = \"Positivo Verdadeiro\"\n",
    "        elif teste['Avaliacao'][i] != p_naive:\n",
    "            teste[\"Resultado\"][i] = \"Positivo Falso\"\n",
    "\n",
    "    elif p_sim < p_nao:\n",
    "        p_naive = 'nao'\n",
    "        teste[\"Avaliacao_nb\"][i] = p_naive\n",
    "        if teste['Avaliacao'][i] == p_naive:\n",
    "            teste[\"Resultado\"][i] = \"Negativo Verdadeiro\"\n",
    "        elif teste['Avaliacao'][i] != p_naive:\n",
    "            teste[\"Resultado\"][i] = \"Negativo Falso\"\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras</th>\n",
       "      <th>Avaliacao</th>\n",
       "      <th>Avaliacao_nb</th>\n",
       "      <th>Resultado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[queria, saber, pq, digio, e, nubank, investem...</td>\n",
       "      <td>sim</td>\n",
       "      <td>nao</td>\n",
       "      <td>Negativo Falso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ainda, nao, temos, previsao, mas, os, nossos,...</td>\n",
       "      <td>nao</td>\n",
       "      <td>nao</td>\n",
       "      <td>Negativo Verdadeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[opa, fica, tranquilo, !, chama, a, gente, la,...</td>\n",
       "      <td>nao</td>\n",
       "      <td>nao</td>\n",
       "      <td>Negativo Verdadeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[chegou, meu, @nubank, agora, #sounu, ğŸ’œ]</td>\n",
       "      <td>nao</td>\n",
       "      <td>nao</td>\n",
       "      <td>Negativo Verdadeiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imagina, !, ğŸ’œ, que, bom, que, gostou, ğŸ˜‰]</td>\n",
       "      <td>nao</td>\n",
       "      <td>nao</td>\n",
       "      <td>Negativo Verdadeiro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            palavras Avaliacao Avaliacao_nb  \\\n",
       "0  [queria, saber, pq, digio, e, nubank, investem...       sim          nao   \n",
       "1  [ainda, nao, temos, previsao, mas, os, nossos,...       nao          nao   \n",
       "2  [opa, fica, tranquilo, !, chama, a, gente, la,...       nao          nao   \n",
       "3           [chegou, meu, @nubank, agora, #sounu, ğŸ’œ]       nao          nao   \n",
       "4          [imagina, !, ğŸ’œ, que, bom, que, gostou, ğŸ˜‰]       nao          nao   \n",
       "\n",
       "             Resultado  \n",
       "0       Negativo Falso  \n",
       "1  Negativo Verdadeiro  \n",
       "2  Negativo Verdadeiro  \n",
       "3  Negativo Verdadeiro  \n",
       "4  Negativo Verdadeiro  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nao    77.0\n",
      "sim    23.0\n",
      "Name: Avaliacao, dtype: float64\n",
      "\n",
      "\n",
      "Negativo Verdadeiro    68.5\n",
      "Negativo Falso         18.0\n",
      "Positivo Falso          8.5\n",
      "Positivo Verdadeiro     5.0\n",
      "Name: Resultado, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(teste[\"Avaliacao\"].value_counts(normalize=True)*100)\n",
    "print('\\n')\n",
    "print(teste[\"Resultado\"].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusÃ£o.<br /> \n",
    "FaÃ§a um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como sÃ£o tratadas as mensagens com dupla negaÃ§Ã£o e sarcasmo.<br />\n",
    "Proponha um plano de expansÃ£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que nÃ£o posso alimentar minha base de Treinamento automaticamente usando o prÃ³prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenÃ¡rios de uso para o classificador Naive-Bayes. CenÃ¡rios sem intersecÃ§Ã£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicaÃ§Ãµes concretas de como implementar (nÃ£o Ã© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos resultados obtidos do classificador Naive Bayes, observou-se uma grande porcentagem de Negativos Falsos(18%) e uma baixa porcentagem de Positivos Verdadeiros(5%), comparando com a base de testes. Isso occoreu devido ao fato de que a base de treinamento utilizada nÃ£o possui tweets suficientes para uma anÃ¡lise consistente e hÃ¡, tambÃ©m, problemas e inversÃµes de sintaxe que o programa nÃ£o consegue detectar, como por exemplo as duplas negaÃ§Ãµes. JÃ¡ os Negativos Verdadeiros obtiveram uma boa performance (de 75% para 68.5%),indicando que o classificador possui uma maior precisÃ£o ao analizar os tweets irrelevantes. Uma possÄ«vel causa para esse comportamento Ã© de que os tweets relevantes tem maior diversidade de conteÃºdo que os irrelevantes, visto que os nÃ£o revelantes se encaixam em basicamente em 3 categorias: conteÃºdo imprÃ³prio, perguntas e citaÃ§Ãµes irrelevantes ao nubank. Essa diferenÃ§a faz com que a base de dados das palavras irrelevantes do classificador seja mais consistente, ou seja, com menos variaÃ§Ã£o de palavras.\n",
    "\n",
    "A respeito dos tweets com dupla negaÃ§Ã£o, pode-se dizer que: as mensagens de dupla negaÃ§Ã£o e sarcasmo sÃ£o interpretadas, na maioria das vezes, como tweets irrelevantes, visto que, para a nossa base de treinamento, os tweets com conotaÃ§Ã£o negativa em sua maior parte sÃ£o irrelevantes. Portanto, a dupla negaÃ§Ã£o em um tweet classificado como relevante aumenta a P(Tweet|Irelevante), de acordo com o mÃ©todo do Naive Bayes, o que o classifica como irrelevante. Isso explica uma parte da grande quantidade de Negativos Falsos obtidos.\n",
    "\n",
    "O projeto \"Classificador AutomÃ¡tico de Sentimento\" deve continuar sendo financiado devido a sua boa porcentagem de acertos de Negativos Verdadeiros (89%), com apenas uma pequena base de dados. Isso irÃ¡ ajudar no filtro para responder os tweets, eliminando a necessidade de um funcionÃ¡rio que analisa os tweets. Dessa forma, a empresa apenas precisarÃ¡ de um funcionÃ¡rio para responder os tweets que jÃ¡ foram prÃ© selecionados pelo classificador. Alguns planos de expansÃ£o para o projeto serÃ£o: o aumento da base de dados, identificar duplas negaÃ§Ãµes, adicionar palavras semelhantes a certos grupos de relevÃ¢ncia, remover artigos e preposiÃ§Ãµes e obter mais nÃ­veis de classificaÃ§Ã£o, como: Muito Relevante, Pouco Relevante, Neutro, Pouco Irrelevante, Muito Irrelevante. Essas melhorias irÃ£o proporcionar uma maior precisÃ£o e uma maior porcentagem de Positivos Verdadeiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
